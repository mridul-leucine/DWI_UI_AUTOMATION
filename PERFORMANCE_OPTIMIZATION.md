# Performance Optimization Guide

## Overview

This document describes performance optimizations implemented in the DWI UI Automation Framework and provides guidance on achieving optimal test execution speed and stability.

## Current Performance Baseline

| Metric | Value |
|--------|-------|
| Test Suite Execution (Single Test) | 5-7 minutes |
| Test Suite Execution (Headless) | 4-6 minutes |
| Test Suite Execution (Parallel, Multiple Tests) | N/A (single test currently) |
| Browser Startup Time | ~2-3 seconds |
| Page Load Average | ~1-2 seconds |

## Implemented Optimizations

### 1. Headless Browser Mode ‚úÖ

**Impact**: 10-20% faster execution

**Configuration**:
```bash
# Run in headless mode
pytest --headless

# Or configure in conftest.py
browser = browser_type.launch(headless=True)
```

**Benefits**:
- No GUI rendering overhead
- Reduced resource usage
- Faster in CI/CD environments

**Drawbacks**:
- Cannot visually observe test execution
- Some UI behaviors may differ slightly

**Recommendation**: Use headless mode for CI/CD, use headed mode for local development and debugging.

### 2. Smart Wait Strategies ‚úÖ

**Impact**: Eliminates unnecessary wait time

**Implementation**:
The framework uses `WaitHelper` utility for intelligent waits:

```python
from utils.wait_helper import WaitHelper

wait_helper = WaitHelper(page)

# ‚úÖ GOOD - Smart wait (waits only as long as needed)
wait_helper.wait_for_element_visible(locator, timeout=5000)
wait_helper.wait_for_element_clickable(locator)

# ‚ùå AVOID - Fixed wait (always waits full duration)
page.wait_for_timeout(5000)
```

**Optimization Opportunities**:
Current POM classes use some fixed 500ms waits that could be replaced with smart waits:

```python
# Current approach
self.page.wait_for_timeout(500)

# Optimized approach
wait_helper.smart_wait(duration=100)  # Adaptive wait
```

### 3. Playwright Auto-Wait ‚úÖ

**Impact**: Built-in actionability checks

**Features**:
- Waits for element to be visible
- Waits for element to be stable (not animating)
- Waits for element to be enabled
- Automatically retries failed actions

**Configuration**:
```python
# Set default timeout (conftest.py)
page.set_default_timeout(30000)  # 30 seconds

# Per-action timeout
locator.click(timeout=10000)  # 10 seconds
```

### 4. Parallel Test Execution ‚úÖ

**Impact**: Linear speedup with multiple tests

**Configuration**:
```bash
# Run tests in parallel (auto-detect CPU cores)
pytest -n auto

# Run with specific number of workers
pytest -n 4

# Use with specific browser
pytest -n auto --browser=chromium --headless
```

**Benefits**:
- Tests run concurrently
- Utilizes multiple CPU cores
- Reduces total execution time

**Limitations**:
- Only beneficial with multiple test files/scenarios
- Current project has single main test (no parallel benefit yet)
- Each worker needs separate browser instance

### 5. Browser Context Optimization ‚úÖ

**Impact**: Faster browser initialization

**Implementation**:
```python
# Optimized browser launch (conftest.py)
browser = browser_type.launch(
    headless=True,
    args=[
        '--disable-extensions',
        '--disable-gpu',
        '--no-sandbox',
        '--disable-dev-shm-usage'
    ]
)
```

**Note**: Currently using default Playwright settings which are already optimized.

### 6. Network Optimization ‚ö° (Optional)

**Impact**: Faster page loads in test environments

**Configuration**:
```python
# Block unnecessary resources (images, fonts, etc.)
context = browser.new_context(
    viewport={"width": 1920, "height": 1080"},
    # Block images for faster loads (optional)
    # ignore_https_errors=True  # For test environments only
)

# Intercept and block requests
page.route("**/*.{png,jpg,jpeg,gif,svg,webp}", lambda route: route.abort())
page.route("**/fonts/**", lambda route: route.abort())
```

**Caution**: May cause test failures if UI depends on blocked resources.

### 7. Page Load Strategy üöÄ (Configurable)

**Impact**: Earlier test interaction, faster execution

**Options**:
```python
# Default: Wait for 'load' event (all resources)
page.goto(url)

# Faster: Wait for 'domcontentloaded' event
page.goto(url, wait_until='domcontentloaded')

# Fastest: Wait for 'commit' event (navigation committed)
page.goto(url, wait_until='commit')

# Network idle: Wait for network to be idle
page.goto(url, wait_until='networkidle')
```

**Current Setting**: Default (wait for 'load')

**Recommendation**: Use 'domcontentloaded' for internal pages, 'load' for initial page load.

## Stability Improvements

### 1. Retry Mechanism ‚úÖ

**Implementation**: Pytest retry plugin

**Installation**:
```bash
pip install pytest-rerun
```

**Usage**:
```bash
# Retry failed tests up to 2 times
pytest --reruns 2

# Retry with delay
pytest --reruns 2 --reruns-delay 1
```

**Configuration in pytest.ini**:
```ini
[pytest]
addopts = --reruns 2 --reruns-delay 1
```

**Test-specific retry**:
```python
@pytest.mark.flaky(reruns=3)
def test_flaky_scenario():
    # Test code
```

### 2. Robust Element Location ‚úÖ

**Best Practices**:
```python
# ‚úÖ BEST - Use data-testid
locator = page.locator("[data-testid='submit-button']")

# ‚úÖ GOOD - Use ID or unique attributes
locator = page.locator("#submit-button")
locator = page.locator("button[name='submit']")

# ‚úÖ OK - Use text content
locator = page.locator("button:has-text('Submit')")

# ‚ö†Ô∏è FRAGILE - Use class names (may change)
locator = page.locator(".btn-primary.submit-btn")

# ‚ùå AVOID - Absolute XPath (breaks easily)
locator = page.locator("xpath=/html/body/div[1]/div[2]/button")

# ‚úÖ ACCEPTABLE - Relative XPath
locator = page.locator("xpath=//button[@type='submit']")
```

**Current Framework**: Uses mix of text content, class names, and relative selectors.

### 3. Stale Element Handling ‚úÖ

**Implementation**:
Playwright automatically handles stale elements by re-querying the DOM.

**Manual Refresh (if needed)**:
```python
# Playwright re-queries automatically
button = page.locator("#submit-button")
button.click()  # Automatically re-locates if stale

# Custom retry logic (WaitHelper)
wait_helper.wait_with_retry(
    action=lambda: button.click(),
    max_retries=3,
    retry_delay=1000
)
```

### 4. Network Stability üåê

**Implementation**:
```python
# Wait for network idle before interacting
page.wait_for_load_state("networkidle")

# Custom network wait
wait_helper.wait_for_ajax_complete(timeout=5000)
```

### 5. Error Recovery üîÑ

**Implementation**:
```python
# Try-catch with retry
try:
    element.click()
except Exception as e:
    logger.warning(f"First attempt failed: {e}, retrying...")
    page.wait_for_timeout(1000)
    element.click()
```

## Performance Tuning Recommendations

### For Local Development

**Goal**: Visibility and debugging
```bash
pytest tests/ --browser=chromium -v -s
```

**Configuration**:
- Headed mode (visual feedback)
- Slower execution (slow_mo=100)
- Verbose logging
- Screenshots on failure

### For CI/CD

**Goal**: Speed and reliability
```bash
pytest tests/ --browser=chromium --headless -n auto --reruns 2
```

**Configuration**:
- Headless mode
- Parallel execution
- Retry on failure
- Minimal logging (INFO level)

### For Nightly Regression

**Goal**: Comprehensive coverage
```bash
./run_cross_browser_tests.sh
pytest tests/ --browser=chromium --browser=firefox --browser=webkit --reruns 1
```

**Configuration**:
- Multiple browsers
- Headless mode
- Single retry
- Full reporting

## Optimization Checklist

- [‚úÖ] Headless mode enabled for CI/CD
- [‚úÖ] Smart wait utilities implemented
- [‚úÖ] Playwright auto-wait configured
- [‚úÖ] Parallel execution supported
- [‚úÖ] Browser context optimized
- [‚ö†Ô∏è] Network optimization (optional, not implemented)
- [‚ö†Ô∏è] Page load strategy (using default)
- [‚úÖ] Retry mechanism available
- [‚úÖ] Robust element selectors
- [‚úÖ] Stale element handling
- [‚úÖ] Error recovery patterns
- [‚úÖ] Performance documentation

## Future Optimization Opportunities

### 1. Page Object Optimization

**Current**: Some fixed waits (500ms) in parameter components

**Opportunity**: Replace with adaptive waits
```python
# Before
self.page.wait_for_timeout(500)

# After
wait_helper.smart_wait(duration=100)  # Waits minimum, checks state
```

**Estimated Impact**: 10-20% faster for parameter filling steps

### 2. Test Data Pre-loading

**Current**: Test data loaded during test execution

**Opportunity**: Pre-load and cache test data
```python
# Singleton pattern for test data (already implemented)
from utils.test_data_manager import get_test_data_manager

data_mgr = get_test_data_manager()  # Cached
```

**Estimated Impact**: Negligible (already optimized)

### 3. Browser Reuse

**Current**: New browser per test

**Opportunity**: Reuse browser context across tests
```python
@pytest.fixture(scope="session")  # Session scope instead of function
def browser_context():
    # ...
```

**Caution**: May cause test interdependencies

**Estimated Impact**: 20-30% faster for multiple tests

### 4. Selective Resource Loading

**Opportunity**: Block non-essential resources (images, fonts)

**Estimated Impact**: 15-25% faster page loads

**Caution**: May affect UI-dependent tests

## Monitoring and Metrics

### Execution Time Tracking

```python
# Add to conftest.py
@pytest.hookimpl(hookwrapper=True)
def pytest_runtest_makereport(item, call):
    outcome = yield
    report = outcome.get_result()

    if report.when == "call":
        duration = report.duration
        logger.info(f"Test {item.name} took {duration:.2f} seconds")
```

### Performance Thresholds

Set acceptable execution time ranges:
```python
# In test
import time

start_time = time.time()
# Test execution
duration = time.time() - start_time

assert duration < 420, f"Test took too long: {duration}s (expected < 7 minutes)"
```

## Quick Reference

### Fastest Configuration
```bash
pytest tests/ --headless --browser=chromium -n auto --reruns 0
```

### Most Stable Configuration
```bash
pytest tests/ --browser=chromium --reruns 3 --reruns-delay 2 -v
```

### Balanced Configuration (Recommended)
```bash
pytest tests/ --headless --browser=chromium --reruns 2 -v
```

## Conclusion

The framework is already optimized for good performance and stability with:
- Smart wait strategies
- Headless mode support
- Parallel execution capability
- Retry mechanisms
- Robust element location

Further optimizations are possible but should be evaluated based on actual performance bottlenecks identified during test execution.

**Current Status**: ‚úÖ **Optimized**

**Recommended Next Steps**:
1. Monitor test execution times
2. Identify specific bottlenecks
3. Apply targeted optimizations
4. Measure impact

---

**Last Updated**: December 2024
**Framework Version**: 1.0.0
